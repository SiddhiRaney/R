#########################################
# 1. Linear Regression
#########################################
library(caret)
data(mtcars)
lr_model <- train(mpg ~ wt + hp, data = mtcars, method = "lm")
summary(lr_model)

#########################################
# 2. Logistic Regression
#########################################
data <- mtcars
data$am <- factor(data$am)
log_model <- glm(am ~ wt + hp, data = data, family = binomial)
summary(log_model)

#########################################
# 3. Decision Tree
#########################################
library(rpart)
library(rpart.plot)
dt_model <- rpart(Species ~ ., data = iris)
rpart.plot(dt_model)

#########################################
# 4. Random Forest
#########################################
library(randomForest)
rf_model <- randomForest(Species ~ ., data = iris, ntree = 200)
print(rf_model)

#########################################
# 5. KNN Classification
#########################################
library(class)
train <- iris[1:100, -5]
test  <- iris[101:150, -5]
train_labels <- iris[1:100, 5]
test_labels  <- iris[101:150, 5]
knn_pred <- knn(train, test, train_labels, k = 5)
table(knn_pred, test_labels)

#########################################
# 6. SVM
#########################################
library(e1071)
svm_model <- svm(Species ~ ., data = iris, kernel = "radial")
svm_pred <- predict(svm_model, iris)
table(svm_pred, iris$Species)

#########################################
# 7. Naive Bayes
#########################################
library(e1071)
nb_model <- naiveBayes(Species ~ ., data = iris)
nb_pred <- predict(nb_model, iris)
table(nb_pred, iris$Species)

#########################################
# 8. K-Means Clustering
#########################################
set.seed(42)
km_model <- kmeans(iris[, 1:4], centers = 3)
print(km_model$cluster)

#########################################
# 9. Hierarchical Clustering
#########################################
dist_mat <- dist(iris[, 1:4])
hc_model <- hclust(dist_mat, method = "complete")
plot(hc_model)

#########################################
# 10. PCA
#########################################
pca_model <- prcomp(iris[, 1:4], scale. = TRUE)
summary(pca_model)
plot(pca_model)

#########################################
# 11. KNN Regression
#########################################
library(kknn)
knnr_model <- kknn(Sepal.Length ~ ., train = iris, test = iris, k = 5)
summary(knnr_model$fit)

#########################################
# 12. XGBoost
#########################################
library(xgboost)
x_data <- as.matrix(iris[, -5])
x_label <- as.numeric(iris$Species) - 1
dtrain <- xgb.DMatrix(data = x_data, label = x_label)
xgb_model <- xgboost(data = dtrain, nrounds = 50, objective = "multi:softprob", num_class = 3)
print(xgb_model)

#########################################
# 13. Lasso Regression
#########################################
library(glmnet)
x <- as.matrix(mtcars[, c("wt", "hp")])
y <- mtcars$mpg
lasso_model <- cv.glmnet(x, y, alpha = 1)
print(lasso_model$lambda.min)

#########################################
# 14. Ridge Regression
#########################################
ridge_model <- cv.glmnet(x, y, alpha = 0)
print(ridge_model$lambda.min)

#########################################
# 15. Elastic Net Regression
#########################################
enet_model <- cv.glmnet(x, y, alpha = 0.5)
print(enet_model$lambda.min)

#########################################
# 16. Gradient Boosting Machine
#########################################
library(gbm)
gbm_model <- gbm(Species ~ ., data = iris, distribution = "multinomial", n.trees = 200, interaction.depth = 3)
summary(gbm_model)

#########################################
# 17. AdaBoost
#########################################
library(ada)
ada_model <- ada(Species ~ ., data = iris, iter = 100)
summary(ada_model)

#########################################
# 18. LightGBM
#########################################
library(lightgbm)
train_data <- lgb.Dataset(data = as.matrix(iris[, -5]), label = x_label)
lgb_model <- lgb.train(params = list(objective = "multiclass", num_class = 3), data = train_data, nrounds = 100)
print(lgb_model)

#########################################
# 19. ANN
#########################################
library(nnet)
ann_model <- nnet(Species ~ ., data = iris, size = 5, maxit = 500)
summary(ann_model)

#########################################
# 20. ARIMA Time Series
#########################################
library(forecast)
ts_model <- auto.arima(AirPassengers)
summary(ts_model)
plot(forecast(ts_model))

#########################################
# 21. LSTM
#########################################
library(keras)
model <- keras_model_sequential() %>%
  layer_lstm(units = 32, input_shape = c(12,1)) %>%
  layer_dense(units = 1)
summary(model)

#########################################
# 22. DBSCAN
#########################################
library(dbscan)
db_model <- dbscan(iris[, 1:4], eps = 0.5, minPts = 5)
print(db_model$cluster)

#########################################
# 23. Gaussian Mixture Model
#########################################
library(mclust)
gmm_model <- Mclust(iris[, 1:4])
summary(gmm_model)

#########################################
# 24. Apriori
#########################################
library(arules)
transactions <- as(as.data.frame(iris[, -5]), "transactions")
rules <- apriori(transactions, parameter = list(supp = 0.1, conf = 0.8))
inspect(rules)

#########################################
# 25. LDA
#########################################
library(MASS)
lda_model <- lda(Species ~ ., data = iris)
lda_pred <- predict(lda_model)$class
table(lda_pred, iris$Species)

#########################################
# 26. QDA
#########################################
qda_model <- qda(Species ~ ., data = iris)
qda_pred <- predict(qda_model)$class
table(qda_pred, iris$Species)

#########################################
# 27. SOM
#########################################
library(kohonen)
som_grid <- somgrid(xdim = 5, ydim = 5, topo = "hexagonal")
som_model <- som(as.matrix(iris[, 1:4]), som_grid)
plot(som_model)

#########################################
# 28. T-SNE
#########################################
library(Rtsne)
tsne_model <- Rtsne(iris[, 1:4])
plot(tsne_model$Y)

#########################################
# 29. Linear SVM
#########################################
svm_linear <- svm(Species ~ ., data = iris, kernel = "linear")
table(predict(svm_linear, iris), iris$Species)

#########################################
# 30. Extra Trees
#########################################
library(extraTrees)
et_model <- extraTrees(x = iris[, -5], y = iris$Species, ntree = 300)
print(et_model)
#########################################
# 31. Bagging
#########################################
library(ipred)
bag_model <- bagging(Species ~ ., data = iris, nbagg = 50)
bag_pred <- predict(bag_model, iris)
table(bag_pred, iris$Species)

#########################################
# 32. Boosted Decision Trees (C5.0)
#########################################
library(C50)
c50_model <- C5.0(Species ~ ., data = iris)
c50_pred <- predict(c50_model, iris)
table(c50_pred, iris$Species)

#########################################
# 33. Principal Component Regression (PCR)
#########################################
library(pls)
pcr_model <- pcr(mpg ~ wt + hp, data = mtcars, scale = TRUE, validation = "CV")
summary(pcr_model)

#########################################
# 34. Partial Least Squares (PLS)
#########################################
pls_model <- plsr(mpg ~ wt + hp, data = mtcars, scale = TRUE, validation = "CV")
summary(pls_model)

#########################################
# 35. Multinomial Logistic Regression
#########################################
library(nnet)
multi_log_model <- multinom(Species ~ ., data = iris)
summary(multi_log_model)

#########################################
# 36. Isolation Forest (Anomaly Detection)
#########################################
library(isotree)
iso_model <- isolation.forest(iris[, 1:4])
iso_score <- predict(iso_model, iris[, 1:4])
summary(iso_score)

#########################################
# 37. Autoencoder
#########################################
library(keras)
ae_model <- keras_model_sequential() %>%
  layer_dense(units = 3, activation = "relu", input_shape = 4) %>%
  layer_dense(units = 4, activation = "linear")
summary(ae_model)

#########################################
# 38. HMM (Hidden Markov Model)
#########################################
library(depmixS4)
hmm_model <- depmix(response = Sepal.Length ~ 1, data = iris, nstates = 3)
hmm_fit <- fit(hmm_model)
summary(hmm_fit)

#########################################
# 39. Cox Proportional Hazards Model
#########################################
library(survival)
cox_model <- coxph(Surv(time = wt, event = hp > 100) ~ mpg, data = mtcars)
summary(cox_model)

#########################################
# 40. Fuzzy C-Means Clustering
#########################################
library(e1071)
fcm_model <- cmeans(iris[, 1:4], centers = 3, m = 2)
print(fcm_model$cluster)
#########################################
# 41. Bayesian Linear Regression
#########################################
library(brms)
bayes_lm <- brm(mpg ~ wt + hp, data = mtcars, chains = 2, iter = 1000)
summary(bayes_lm)

#########################################
# 42. Bayesian Logistic Regression
#########################################
bayes_log <- brm(am ~ wt + hp, data = mtcars, family = bernoulli(), chains = 2)
summary(bayes_log)

#########################################
# 43. CART Regression Tree
#########################################
library(rpart)
cart_reg <- rpart(mpg ~ wt + hp, data = mtcars)
print(cart_reg)

#########################################
# 44. CART Classification Tree
#########################################
cart_clf <- rpart(Species ~ ., data = iris)
print(cart_clf)

#########################################
# 45. Multivariate Adaptive Regression Splines (MARS)
#########################################
library(earth)
mars_model <- earth(mpg ~ wt + hp, data = mtcars)
summary(mars_model)

#########################################
# 46. Probabilistic PCA
#########################################
library(pcaMethods)
ppca_model <- pca(iris[,1:4], method = "ppca")
summary(ppca_model)

#########################################
# 47. Robust Regression
#########################################
library(MASS)
robust_model <- rlm(mpg ~ wt + hp, data = mtcars)
summary(robust_model)

#########################################
# 48. Quantile Regression
#########################################
library(quantreg)
qr_model <- rq(mpg ~ wt + hp, data = mtcars, tau = 0.5)
summary(qr_model)

#########################################
# 49. One-Class SVM (Anomaly Detection)
#########################################
library(e1071)
ocsvm_model <- svm(iris[,1:4], type = "one-classification", kernel = "radial")
summary(ocsvm_model)

#########################################
# 50. Association Rule Mining â€“ Eclat
#########################################
library(arules)
eclat_rules <- eclat(transactions, parameter = list(supp = 0.1, maxlen = 5))
inspect(eclat_rules)
#########################################
# 51. Huber Regression
#########################################
library(MASS)
huber_model <- rlm(mpg ~ wt + hp, data = mtcars, psi = psi.huber)
summary(huber_model)

#########################################
# 52. Generalized Additive Model (GAM)
#########################################
library(mgcv)
gam_model <- gam(mpg ~ s(wt) + s(hp), data = mtcars)
summary(gam_model)
plot(gam_model)

#########################################
# 53. Bayesian Network
#########################################
library(bnlearn)
bn_data <- iris
bn_model <- hc(bn_data)
plot(bn_model)

#########################################
# 54. Canonical Correlation Analysis (CCA)
#########################################
x_vars <- iris[, 1:2]
y_vars <- iris[, 3:4]
cca_model <- cancor(x_vars, y_vars)
print(cca_model$cor)

#########################################
# 55. Multidimensional Scaling (MDS)
#########################################
dist_iris <- dist(iris[, 1:4])
mds_model <- cmdscale(dist_iris)
plot(mds_model, col = as.numeric(iris$Species))

#########################################
# 56. Independent Component Analysis (ICA)
#########################################
library(fastICA)
ica_model <- fastICA(iris[, 1:4], n.comp = 2)
plot(ica_model$S)

#########################################
# 57. Extreme Learning Machine (ELM)
#########################################
library(elmNN)
elm_model <- elmtrain(as.matrix(iris[,1:4]), as.numeric(iris$Species), nhid = 10)
print(elm_model)

#########################################
# 58. Zero-Inflated Poisson Regression
#########################################
library(pscl)
zip_model <- zeroinfl(mpg ~ wt + hp | wt, data = mtcars)
summary(zip_model)

#########################################
# 59. Poisson Regression
#########################################
pois_model <- glm(mpg ~ wt + hp, data = mtcars, family = poisson())
summary(pois_model)

#########################################
# 60. Negative Binomial Regression
#########################################
library(MASS)
nb_model <- glm.nb(mpg ~ wt + hp, data = mtcars)
summary(nb_model)
#########################################
# 61. Multilevel / Mixed Effects Model
#########################################
library(lme4)
mixed_model <- lmer(mpg ~ wt + hp + (1 | cyl), data = mtcars)
summary(mixed_model)

#########################################
# 62. Generalized Linear Mixed Model (GLMM)
#########################################
glmm_model <- glmer(am ~ wt + hp + (1 | cyl),
                    data = mtcars,
                    family = binomial)
summary(glmm_model)

#########################################
# 63. Tobit Regression
#########################################
library(AER)
tobit_model <- tobit(mpg ~ wt + hp, data = mtcars, left = 10)
summary(tobit_model)

#########################################
# 64. Probit Regression
#########################################
probit_model <- glm(am ~ wt + hp,
                    data = mtcars,
                    family = binomial(link = "probit"))
summary(probit_model)

#########################################
# 65. Multivariate Linear Regression
#########################################
multi_lm <- lm(cbind(mpg, disp) ~ wt + hp, data = mtcars)
summary(multi_lm)

#########################################
# 66. Structural Equation Modeling (SEM)
#########################################
library(lavaan)
sem_model <- '
  mpg ~ wt + hp
  disp ~ wt
'
fit_sem <- sem(sem_model, data = mtcars)
summary(fit_sem)

#########################################
# 67. Gaussian Process Regression
#########################################
library(kernlab)
gpr_model <- gausspr(mpg ~ wt + hp, data = mtcars)
summary(gpr_model)

#########################################
# 68. Rule-Based Classifier (PART)
#########################################
library(RWeka)
part_model <- PART(Species ~ ., data = iris)
summary(part_model)

#########################################
# 69. Self-Training Semi-Supervised Learning
#########################################
library(RSSL)
semi_model <- SelfLearning(Species ~ ., data = iris)
summary(semi_model)

#########################################
# 70. Spectral Clustering
#########################################
library(kernlab)
spec_model <- specc(as.matrix(iris[, 1:4]), centers = 3)
plot(spec_model, col = as.numeric(spec_model))
#########################################
# 71. K-Medoids Clustering (PAM)
#########################################
library(cluster)
pam_model <- pam(iris[, 1:4], k = 3)
print(pam_model$clustering)

#########################################
# 72. Affinity Propagation
#########################################
library(apcluster)
ap_model <- apcluster(negDistMat(r=2), iris[,1:4])
show(ap_model)

#########################################
# 73. Sparse Logistic Regression
#########################################
library(glmnet)
x <- as.matrix(iris[,1:4])
y <- as.numeric(iris$Species) - 1
sparse_log <- cv.glmnet(x, y, family = "multinomial", alpha = 1)
print(sparse_log$lambda.min)

#########################################
# 74. Robust PCA
#########################################
library(rrcov)
rpca_model <- PcaHubert(iris[,1:4])
summary(rpca_model)

#########################################
# 75. Polynomial Regression
#########################################
poly_model <- lm(mpg ~ poly(wt, 2) + poly(hp, 2), data = mtcars)
summary(poly_model)

#########################################
# 76. LOESS Regression
#########################################
loess_model <- loess(mpg ~ wt, data = mtcars)
summary(loess_model)

#########################################
# 77. Conditional Inference Tree
#########################################
library(party)
ctree_model <- ctree(Species ~ ., data = iris)
plot(ctree_model)

#########################################
# 78. Conditional Random Forest
#########################################
library(party)
crf_model <- cforest(Species ~ ., data = iris)
print(crf_model)

#########################################
# 79. Copula Model
#########################################
library(copula)
norm_cop <- normalCopula(dim = 2)
fit_cop <- fitCopula(norm_cop, iris[,1:2], method = "ml")
summary(fit_cop)

#########################################
# 80. Empirical Bayesian Estimation
#########################################
library(ebayes)
eb_model <- ebayes(lm(mpg ~ wt + hp, data = mtcars))
summary(eb_model)

#########################################
# 81. Factor Analysis
#########################################
fa_model <- factanal(iris[, 1:4], factors = 2, rotation = "varimax")
print(fa_model)

#########################################
# 82. Non-negative Matrix Factorization (NMF)
#########################################
library(NMF)
nmf_model <- nmf(as.matrix(iris[, 1:4]), rank = 2)
summary(nmf_model)

#########################################
# 83. Ridge Logistic Regression
#########################################
library(glmnet)
x <- as.matrix(iris[, 1:4])
y <- as.numeric(iris$Species) - 1
ridge_log <- cv.glmnet(x, y, family = "multinomial", alpha = 0)
print(ridge_log$lambda.min)

#########################################
# 84. Bayesian Additive Regression Trees (BART)
#########################################
library(BART)
bart_model <- gbart(x, y)
print(bart_model)

#########################################
# 85. Tweedie Regression
#########################################
library(statmod)
tweedie_model <- glm(mpg ~ wt + hp, data = mtcars,
                     family = tweedie(var.power = 1.5, link.power = 0))
summary(tweedie_model)

#########################################
# 86. Zero-Inflated Negative Binomial
#########################################
library(pscl)
zinb_model <- zeroinfl(mpg ~ wt + hp | wt, data = mtcars, dist = "negbin")
summary(zinb_model)

#########################################
# 87. Bayesian PCA
#########################################
library(pcaMethods)
bpca_model <- pca(iris[,1:4], method = "bpca")
summary(bpca_model)

#########################################
# 88. Kernel PCA
#########################################
library(kernlab)
kpca_model <- kpca(~., data = iris[,1:4], kernel = "rbfdot")
plot(rotated(kpca_model))

#########################################
# 89. Multiclass Probit Model
#########################################
library(MNP)
mnp_model <- mnp(Species ~ ., data = iris, burnin = 100, mcmc = 500)
summary(mnp_model)

#########################################
# 90. Sparse PCA
#########################################
library(elasticnet)
spca_model <- spca(as.matrix(iris[,1:4]), K = 2)
print(spca_model)
